# Week 5-6, Days 31-33: Advanced RAG Techniques

## üöÄ Overview

This week focuses on **advanced Retrieval Augmented Generation (RAG) techniques** that move beyond basic document Q&A. You'll learn sophisticated methods for improving search quality, re-ranking results, and handling multiple document collections.

## üéØ Learning Objectives

By the end of this week, you will be able to:

1. **Implement hybrid search** combining multiple retrieval algorithms
2. **Apply advanced re-ranking** to improve result quality
3. **Build multi-document assistants** with intelligent query routing
4. **Optimize RAG systems** for production use cases
5. **Evaluate and benchmark** different RAG approaches

## üìÅ Files in This Directory

### 1. `hybrid_search.py`
**Advanced hybrid search system combining multiple algorithms:**

**Key Features:**
- **Semantic Search**: Vector embeddings for meaning-based retrieval
- **Keyword Search**: TF-IDF for term-based matching
- **BM25 Search**: Advanced probabilistic retrieval
- **Hybrid Fusion**: Weighted combination of multiple algorithms
- **Reciprocal Rank Fusion (RRF)**: Advanced result combination
- **Query Expansion**: Automatic query improvement
- **Performance Benchmarking**: Compare different search algorithms

**Algorithms Implemented:**
- Semantic embeddings (OpenAI/HuggingFace)
- TF-IDF with n-grams
- BM25 with text preprocessing
- Weighted hybrid fusion
- Dense search (semantic + keyword)
- Position-aware re-ranking

### 2. `reranking.py`
**Advanced re-ranking system for improving search results:**

**Key Features:**
- **Cross-Encoder Re-ranking**: Sentence Transformers for relevance scoring
- **TF-IDF Re-ranking**: Text feature-based improvement
- **Semantic Re-ranking**: Embedding-based relevance
- **Hybrid Re-ranking**: Multiple factor combination
- **Positional Re-ranking**: Document structure awareness
- **Ensemble Re-ranking**: Combined multiple algorithms
- **Evaluation Framework**: Comprehensive metrics and benchmarking

**Re-ranking Techniques:**
- Cross-encoder models (ms-marco, MiniLM)
- Text feature extraction (term overlap, distribution, position)
- Freshness and authority scoring
- Diversity optimization
- NDCG and precision@k evaluation

### 3. `multi_doc_assistant.py`
**Sophisticated multi-document assistant with advanced features:**

**Key Features:**
- **Multiple Document Collections**: Organize documents by type/category
- **Intelligent Query Routing**: Automatic collection selection
- **Cross-Collection Retrieval**: Search across all relevant collections
- **Advanced Answer Synthesis**: Context-aware response generation
- **Conversation Memory**: Maintain context across interactions
- **Confidence Scoring**: Measure answer reliability
- **Citation Generation**: Automatic source attribution

**Collection Types Supported:**
- Technical documentation
- Research papers
- Legal documents
- Medical information
- Financial reports
- Personal notes
- General knowledge

## üöÄ Getting Started

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Additional setup for spaCy
python -m spacy download en_core_web_sm

# Set up environment variables
echo "OPENAI_API_KEY=your-api-key-here" > .env
Basic Usage Examples
Hybrid Search
python
from hybrid_search import HybridSearchSystem, HybridSearchConfig

# Configure hybrid search
config = HybridSearchConfig(
    semantic_weight=0.5,
    keyword_weight=0.3,
    bm25_weight=0.2,
    alpha=0.7
)

# Initialize system
search = HybridSearchSystem(config)
search.add_documents(documents)

# Perform search
results = search.search("artificial intelligence", k=10)

# Get detailed explanation
explanation = search.search_with_explain("machine learning")
Advanced Re-ranking
python
from reranking import RerankerFactory, RerankerConfig

# Create re-ranker
config = RerankerConfig(
    reranker_type="cross_encoder",
    top_k=5,
    use_cache=True
)
reranker = RerankerFactory.create_reranker("cross_encoder", config)

# Re-rank results
reranked = reranker.rerank(query, documents, original_scores)

# Evaluate multiple re-rankers
from reranking import AdvancedRerankingSystem
system = AdvancedRerankingSystem()
system.evaluate_rerankers(query, documents, ground_truth)
Multi-Document Assistant
python
from multi_doc_assistant import MultiDocumentAssistant, DocumentCollection

# Initialize assistant
assistant = MultiDocumentAssistant(llm_model="gpt-4")

# Create collections
assistant.create_collection(
    name="Technical Docs",
    collection_type=DocumentCollection.TECHNICAL,
    documents=tech_documents
)

# Ask questions
response = assistant.ask("Explain neural networks")
print(response.answer)
print(f"Confidence: {response.confidence:.2%}")
üß™ Key Concepts
1. Hybrid Search Architecture
text
User Query ‚Üí Query Expansion ‚Üí Multiple Searches ‚Üí Result Fusion ‚Üí Re-ranking ‚Üí Final Results
           ‚Üì                ‚Üì                 ‚Üì              ‚Üì           ‚Üì
       Semantic         Keyword           BM25           RRF        Cross-Encoder
        Search          Search           Search         Fusion       Re-ranking
2. Re-ranking Pipeline
text
Initial Results ‚Üí Feature Extraction ‚Üí Relevance Scoring ‚Üí Score Normalization ‚Üí Re-sorting
     ‚Üì                    ‚Üì                   ‚Üì                   ‚Üì              ‚Üì
  Top K docs        Term overlap        Cross-encoder      Min-max scaling   Final ranking
                  Position scoring      TF-IDF features       Ensemble
                  Freshness/Authority   Semantic similarity
3. Multi-Document Assistant Flow
text
User Query ‚Üí Query Analysis ‚Üí Collection Routing ‚Üí Cross-Collection Search ‚Üí Answer Synthesis
    ‚Üì              ‚Üì               ‚Üì                   ‚Üì                      ‚Üì
   Input      Type detection    Which collections   Retrieve from      Generate answer
              Keyword extraction  to search?        multiple sources   with citations
              Complexity assessment
üìä Performance Optimization
Search Optimization
python
# Optimal configuration for hybrid search
config = HybridSearchConfig(
    semantic_weight=0.6,    # Higher for semantic queries
    keyword_weight=0.3,     # Medium for term matching
    bm25_weight=0.1,        # Lower for general cases
    alpha=0.7,              # Higher for RRF dominance
    k=10,                   # Retrieve more initially
    rerank_top_k=5          # Re-rank top results
)
Re-ranking Optimization
python
# Best practices for re-ranking
config = RerankerConfig(
    reranker_type="ensemble",      # Use ensemble for best results
    top_k=10,                      # Re-rank more documents
    diversity_weight=0.2,          # Balance relevance and diversity
    position_weight=0.1,           # Consider document structure
    use_cache=True,                # Cache for performance
    cache_size=1000                # Reasonable cache size
)
Assistant Optimization
python
# Multi-document assistant tips
assistant = MultiDocumentAssistant(
    llm_model="gpt-4",            # Use best model available
    embedding_model="openai",     # OpenAI embeddings for quality
    persist_base="./data/assistant"  # Organized storage
)
üß™ Testing & Evaluation
Benchmarking Search Algorithms
python
# Run comprehensive benchmark
benchmark = search_system.benchmark_search(
    queries=["AI", "machine learning", "neural networks"],
    search_types=["semantic", "keyword", "bm25", "hybrid"]
)

# Analyze results
print(f"Fastest: {benchmark['fastest']}")
print(f"Most Accurate: {benchmark['most_accurate']}")
Evaluating Re-ranking
python
# Evaluate with ground truth
evaluation = system.evaluate_rerankers(
    query="artificial intelligence",
    documents=documents,
    ground_truth=[0, 2, 4],  # Indices of relevant documents
    original_scores=original_scores
)

# Calculate metrics
print(f"NDCG@5: {evaluation['metrics']['ndcg@5']:.4f}")
print(f"Precision@3: {evaluation['metrics']['precision@3']:.4f}")
Assistant Performance
python
# Get assistant statistics
stats = assistant.get_statistics()
print(f"Avg Processing Time: {stats['avg_processing_time_ms']:.0f}ms")
print(f"Queries Processed: {stats['queries_processed']}")
print(f"Collections: {stats['collections_count']}")
üöÄ Production Deployment
Configuration Management
python
# Environment-based configuration
import os
from dataclasses import asdict

config = HybridSearchConfig(
    semantic_weight=float(os.getenv("SEMANTIC_WEIGHT", "0.6")),
    keyword_weight=float(os.getenv("KEYWORD_WEIGHT", "0.3")),
    k=int(os.getenv("SEARCH_K", "10"))
)

# Save configuration
with open("config.json", "w") as f:
    json.dump(asdict(config), f, indent=2)
Caching Strategies
python
# Implement caching for performance
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def cached_search(query: str, search_type: str):
    """Cached search function"""
    query_hash = hashlib.md5(f"{query}_{search_type}".encode()).hexdigest()
    # ... search implementation
Monitoring & Logging
python
# Comprehensive logging
import logging
import structlog

logging.basicConfig(level=logging.INFO)
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer(),
    ]
)

logger = structlog.get_logger()
logger.info("Search performed", query=query, results=len(results))
üìà Advanced Techniques
1. Dynamic Weight Adjustment
python
# Adjust weights based on query type
def adjust_weights(query: str) -> Tuple[float, float, float]:
    """Dynamically adjust search weights"""
    if "technical" in query.lower():
        return 0.7, 0.2, 0.1  # More semantic, less keyword
    elif "definition" in query.lower():
        return 0.4, 0.5, 0.1  # Balanced
    else:
        return 0.6, 0.3, 0.1  # Default
2. Query Understanding
python
# Advanced query analysis
def analyze_query(query: str) -> Dict:
    """Comprehensive query analysis"""
    return {
        "type": classify_query_type(query),
        "complexity": calculate_complexity(query),
        "entities": extract_entities(query),
        "intent": detect_intent(query),
        "expansion_terms": generate_expansion_terms(query)
    }
3. Result Diversification
python
# Ensure diverse results
def diversify_results(results: List, max_similarity: float = 0.8):
    """Remove similar results to increase diversity"""
    diversified = []
    seen_embeddings = []
    
    for result in results:
        embedding = get_embedding(result.content)
        similar = any(
            cosine_similarity(embedding, seen) > max_similarity
            for seen in seen_embeddings
        )
        
        if not similar:
            diversified.append(result)
            seen_embeddings.append(embedding)
    
    return diversified
üêõ Troubleshooting
Common Issues & Solutions
Slow Search Performance

python
# Solutions:
config = HybridSearchConfig(
    k=5,                    # Reduce initial retrieval
    use_cache=True,         # Enable caching
    rerank_top_k=3          # Re-rank fewer documents
)
Low Answer Quality

python
# Solutions:
assistant = MultiDocumentAssistant(
    llm_model="gpt-4",      # Use better model
    embedding_model="openai"  # Use better embeddings
)
High Memory Usage

python
# Solutions:
config = RerankerConfig(
    cache_size=500,         # Reduce cache size
    max_results=5           # Return fewer results
)
Poor Re-ranking Results

python
# Solutions:
reranker = RerankerFactory.create_reranker(
    "ensemble",             # Use ensemble for robustness
    RerankerConfig(top_k=10)  # Re-rank more documents
)
Debug Mode
python
# Enable detailed logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Test individual components
print("Testing search...")
results = search_system.search("test", k=3)
print(f"Found {len(results)} results")

print("Testing re-ranking...")
reranked = reranker.rerank("test", documents)
print(f"Improvement: {reranked[0].improvement:.4f}")
üìö Project Ideas
Beginner Projects
Document Search Engine: Basic hybrid search for personal documents

Research Paper Assistant: Help find and summarize academic papers

FAQ Generator: Create FAQs from documentation using RAG

Intermediate Projects
Legal Document Analyzer: Multi-collection assistant for legal research

Medical Literature Review: Assist with medical research and summaries

Technical Support Bot: Answer technical questions from documentation

Advanced Projects
Enterprise Knowledge Base: Company-wide multi-document assistant

Research Collaboration Platform: Advanced search and synthesis for research teams

Personal AI Assistant: Multi-source assistant for personal information management

üéØ Next Steps
Phase 3: Web AI & Deployment
API Development: Create REST APIs for your RAG systems

Web Interface: Build user interfaces for document management

Deployment: Docker containers and cloud deployment

Monitoring: Performance monitoring and analytics

Advanced Topics
Multimodal RAG: Combine text with images and other media

Real-time RAG: Process streaming documents

Federated RAG: Distributed document collections

Privacy-preserving RAG: Secure document processing

ü§ù Contributing
Found a bug or have a feature request? Please open an issue or submit a pull request.

üìÑ License
This project is part of the AI Developer Roadmap. Use it for learning and building production AI applications!

Congratulations on completing Phase 2! üéâ

You now have a comprehensive toolkit for building advanced RAG systems. These skills will serve as the foundation for the web deployment and production systems you'll build in Phase 3.

Happy Building! üöÄ